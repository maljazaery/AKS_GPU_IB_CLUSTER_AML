{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7363187c",
      "metadata": {},
      "source": [
        "# Azure ML on AKS with Infiniband: End-to-End Guide\n",
        "---\n",
        "**Table of Contents**\n",
        "1. [Introduction](#1-introduction)\n",
        "2. [Admin Machine Setup](#2-admin-machine-setup)\n",
        "3. [Install Required Tools](#3-install-required-tools)\n",
        "4. [Set Environment Variables](#4-set-environment-variables)\n",
        "5. [Azure Login](#5-azure-login)\n",
        "6. [Install Helm and Kubectl](#6-install-helm-and-kubectl)\n",
        "7. [Create AKS Cluster and Worker Nodes](#7-create-aks-cluster-and-worker-nodes)\n",
        "8. [Install Hardware Management Components](#8-install-hardware-management-components)\n",
        "9. [Attach AKS to AzureML](#9-attach-aks-to-azureml)\n",
        "10. [Validate Infiniband Performance](#10-validate-infiniband-performance)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6ddc3fb",
      "metadata": {},
      "source": [
        "## 1. Introduction\n",
        "\n",
        "This tutorial will take you through creating an AML (Azure Machine Learning) compute backed by an AKS (Azure Kubernetes Service) cluster and running a distributed training job on it with Infiniband support.\n",
        "\n",
        "The setup for this involves setup across 3 main components:\n",
        "- **Admin machine**\n",
        "- **Azure resources**\n",
        "- **Kubernetes cluster**\n",
        "\n",
        "Here is a diagram showing the high level setup architecture:\n",
        "\n",
        "<img src=\"./assets/arch.png\" width=\"1000\">\n",
        "\n",
        "The Admin machine component is the computer you will use to run all the commands and prepare the Kubernetes cluster for distributed training. This must be a Linux-based machine."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20087a7f",
      "metadata": {},
      "source": [
        "## 2. Admin Machine Setup\n",
        "\n",
        "You can use an Azure ML Compute Instance to follow this tutorial, although any Linux machine will do.\n",
        "\n",
        "We will use the AML compute instance as the base. Create a general purpose compute with 2-4 cores and 8-16 GB of RAM. Enable SSH access, root access, and add your public key.\n",
        "\n",
        "<img src=\"./assets/admin-mac.png\" width=\"1000\">\n",
        "\n",
        "Connect to it using VS Code and copy this notebook onto the Compute Instance and open it. This will simplify the setup a lot.\n",
        "\n",
        "<img src=\"./assets/vscode-connect.png\" width=\"1000\">\n",
        "\n",
        "Next, we will manage az CLI component versions and upgrades. The next section will also install az CLI if not present."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32709093",
      "metadata": {},
      "source": [
        "# 3. Install Required Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a92917f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# This cell checks for Azure CLI and installs it if missing, then installs required extensions.\n",
        "\n",
        "if ! command -v az &> /dev/null; then\n",
        "    echo \"Azure CLI not found. Installing Azure CLI...\"\n",
        "    curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n",
        "    echo \"Azure CLI installation completed.\"\n",
        "else\n",
        "    echo \"Azure CLI is already installed. Version: $(az version --query '\"azure-cli\"' -o tsv)\"\n",
        "fi\n",
        "\n",
        "# Remove any old extensions to avoid conflicts\n",
        "sudo az extension remove -n azure-cli-ml\n",
        "sudo az extension remove -n ml\n",
        "\n",
        "# Add required extensions\n",
        "az extension add -n ml\n",
        "az extension add -n k8s-extension\n",
        "az extension add --name aks-preview --allow-preview true"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "759b5f93",
      "metadata": {},
      "source": [
        "## 4. Set Environment Variables\n",
        "\n",
        "Set the following environment variables for your Azure subscription, resource group, workspace, and AKS cluster configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c0c59f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set your Azure and AKS configuration here\n",
        "import os\n",
        "\n",
        "# Fill in your Azure subscription and resource details\n",
        "os.environ[\"SUBSCRIPTION_ID\"] = \"\"  # Azure Subscription ID\n",
        "os.environ[\"RESOURCE_GROUP\"] = \"\"   # Resource Group Name\n",
        "os.environ[\"WORKSPACE\"] = \"\"        # AzureML Workspace Name\n",
        "os.environ[\"LOCATION\"] = \"\"         # e.g., eastus, westus2, etc.\n",
        "os.environ[\"PPG\"] = \"PPGNDH100\"     # Proximity Placement Group name\n",
        "os.environ[\"AKS_CLUSTER\"] = \"NDh100\" # AKS Cluster name (will be created)\n",
        "os.environ[\"AKS_NODE_COUNT\"] = \"2\"  # Number of nodes in the AKS cluster\n",
        "os.environ[\"AKS_NODE_VM_SIZE\"] = \"standard_nd96isr_h100_v5\"  # VM size for the AKS nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "364c0536",
      "metadata": {},
      "source": [
        "## 5. Azure Login\n",
        "\n",
        "Open a terminal on your machine and run `az login` before continuing. \\\n",
        "Login is an interactive process and requires input for the user tenant and subscription selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "148040f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# This cell ensures you do not accidentally run the entire notebook without logging in.\n",
        "# SKIP RUNNING THIS SECTION AFTER YOU LOG IN IN THE PREVIOUS STEP.\n",
        "az login --identity\n",
        "exit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b3ccd6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Set your Azure subscription and register required features\n",
        "\n",
        "az account set --subscription $SUBSCRIPTION_ID\n",
        "az configure --defaults workspace=$WORKSPACE group=$RESOURCE_GROUP location=$LOCATION\n",
        "az feature register --name AKSInfinibandSupport --namespace Microsoft.ContainerService\n",
        "az provider register -n Microsoft.ContainerService"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd67a555",
      "metadata": {},
      "source": [
        "## 6. Install Helm and Kubectl\n",
        "\n",
        "Helm is a package manager for Kubernetes, and we will use it to install Nvidia components. \\\n",
        "Kubectl is a tool to operate Kubernetes clusters through CLI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "622e6d6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Install kubectl and helm, add Nvidia Helm repo\n",
        "\n",
        "sudo snap install kubectl --classic\n",
        "curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 \\\n",
        "    && chmod 700 get_helm.sh \\\n",
        "    && ./get_helm.sh\n",
        "rm get_helm.sh\n",
        "helm repo add nvidia https://helm.ngc.nvidia.com/nvidia\n",
        "helm repo update"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97e5d6be",
      "metadata": {},
      "source": [
        "## 7. Create AKS Cluster and Worker Nodes\n",
        "\n",
        "We need the PPG setting to ensure that the nodes are colocated in the data center and the interconnect is IB. \\\n",
        "This reduces fault tolerance and chances of GPU allocation. \\\n",
        "For Hot SKUs the changes of getting allocation are low, if the allocation fails repeat without PPG. The impact will be slower IB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46be1202-a54b-4ccc-bbb7-3469911f6276",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Create Proximity Placement Group (PPG) for AKS nodes\n",
        "\n",
        "az ppg create \\\n",
        "--name $PPG \\\n",
        "--resource-group $RESOURCE_GROUP \\\n",
        "--location $LOCATION \\\n",
        "--intent-vm-sizes $AKS_NODE_VM_SIZE \\\n",
        "--zone 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea7a4b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Create AKS cluster\n",
        "\n",
        "export PPG_ID=$(az ppg show -n $PPG --query 'id' -o tsv)\n",
        "\n",
        "az aks create \\\n",
        "--name $AKS_CLUSTER \\\n",
        "--node-vm-size Standard_D8s_v3 \\\n",
        "--location $LOCATION \\\n",
        "--node-count 1 \\\n",
        "--nodepool-name masterpool \\\n",
        "--enable-managed-identity \\\n",
        "--generate-ssh-keys # \\\n",
        "# --ppg $PPG_ID # Uncomment this and above line to add PPG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9beeeb3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Add worker node pool with IB support\n",
        "\n",
        "az aks nodepool add \\\n",
        "--cluster-name $AKS_CLUSTER \\\n",
        "--node-vm-size $AKS_NODE_VM_SIZE  \\\n",
        "--gpu-driver none \\\n",
        "--nodepool-name workerpool \\\n",
        "--enable-node-public-ip \\\n",
        "--node-count $AKS_NODE_COUNT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "499e6cbc-32a1-4525-9746-3948d17d693e",
      "metadata": {
        "gather": {
          "logged": 1760736207103
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Get AKS credentials (can be run again if needed)\n",
        "\n",
        "az aks get-credentials \\\n",
        "--resource-group $RESOURCE_GROUP \\\n",
        "--name $AKS_CLUSTER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13936f7a",
      "metadata": {},
      "source": [
        "## 8. Install Hardware Management Components\n",
        "\n",
        "This section installs:\n",
        "1. **Node Feature Discovery:** Dynamically detects and tags available hardware on current and new nodes.\n",
        "2. **Network Operator:** Installs Mellanox NIC driver and exposes them to Kubernetes. Also configures routing rules.\n",
        "3. **GPU Operator:** Installs the drivers for Nvidia GPU and exposes them to Kubernetes.\n",
        "\n",
        "This requires configuration files for Helm charts. These should have come with this tutorial; please add them in the same folder as this notebook.\n",
        "\n",
        "We will also install the [Azure Machine Learning Kubernetes Extension](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-kubernetes-extension?view=azureml-api-2&tabs=deploy-extension-with-cli). This installs components on Kubernetes which allow AzureML to use it as an attached compute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a22df9-3e8b-462e-b9c9-cd43b2daab13",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Install Node Feature Discovery\n",
        "\n",
        "helm install node-feature-discovery node-feature-discovery \\\n",
        "--create-namespace \\\n",
        "--namespace nfd-ns \\\n",
        "--repo https://kubernetes-sigs.github.io/node-feature-discovery/charts \\\n",
        "--version v0.15.6 \\\n",
        "--values nfd-helm.yaml \\\n",
        "--wait"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5edd239b",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Install Network Operator,\n",
        "\n",
        "helm install nvidia/network-operator \\\n",
        "--version 24.10.0 \\\n",
        "--generate-name \\\n",
        "--create-namespace \\\n",
        "--namespace no-ns \\\n",
        "--values nfd-helm.yaml \\\n",
        "--wait\n",
        "kubectl apply -f nic-cluster-policy.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f11d21fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# GPU Operator\n",
        "\n",
        "# nvidia driver version 570\n",
        "# kernel version: 5.15.0-1092-azure\n",
        "helm install nvidia/gpu-operator \\\n",
        "--version 25.3.4 \\\n",
        "--generate-name \\\n",
        "--create-namespace \\\n",
        "--namespace gpu-ns \\\n",
        "--values gpu-operator-helm.yaml \\\n",
        "--wait\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d57078b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# AML K8s Extension\n",
        "\n",
        "az k8s-extension create \\\n",
        "--name aml-k8s-extension \\\n",
        "--extension-type Microsoft.AzureML.Kubernetes \\\n",
        "--config enableTraining=True \\\n",
        "--cluster-type managedClusters \\\n",
        "--cluster-name $AKS_CLUSTER \\\n",
        "--scope cluster \\\n",
        "--auto-upgrade false \\\n",
        "--release-train staging \\\n",
        "--version 1.1.146 # This version has IB support"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a8b1e7",
      "metadata": {},
      "source": [
        "## 9. Attach AKS to AzureML\n",
        "\n",
        "Now the cluster is ready, we will attach it to AzureML to use as a compute.\n",
        "\n",
        "For Kubernetes computes, we must define the [instance type](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-kubernetes-instance-types?view=azureml-api-2&tabs=select-instancetype-to-trainingjob-with-cli%2Cselect-instancetype-to-modeldeployment-with-cli%2Cdefine-resource-to-modeldeployment-with-cli), which represents the specs of a single node of your training job. We will create an instance type which consumes all resources of 1 worker node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e536d9b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Attach AKS cluster to AzureML and apply instance type\n",
        "\n",
        "az ml compute attach \\\n",
        "--resource-group $RESOURCE_GROUP \\\n",
        "--workspace-name $WORKSPACE \\\n",
        "--type Kubernetes \\\n",
        "--name \"kube-compute\" \\\n",
        "--resource-id \"/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.ContainerService/managedclusters/$AKS_CLUSTER\" \\\n",
        "--identity-type SystemAssigned\n",
        "\n",
        "kubectl apply -f instance_type.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d35b1c45",
      "metadata": {},
      "source": [
        "## 10. Validate Infiniband Performance\n",
        "\n",
        "The setup is now complete. AKS training is an existing feature of AML; this article is about performant training through Infiniband.\n",
        "\n",
        "With that in mind, we will run the [nccl-test](https://github.com/NVIDIA/nccl) to validate Infiniband performance. All-reduce under nccl-test is a job which causes large data transfer from each node to all other nodes; we measure the bus speed under the stress of this job.\n",
        "\n",
        "The bus speed is a number representing the performance of the network, agnostic of the number of nodes (i.e., GPUs/ranks) used in the test.\n",
        "\n",
        "<img src=\"./assets/all_reduce.png\" width=600>\n",
        "\n",
        "To run this test, we will first build an AzureML environment with a suitable docker image and nccl-test installed. Environment creation should take about 30 mins to complete, then we will run a job in that environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "646dd067",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Create AzureML environment for NCCL test\n",
        "\n",
        "az ml environment create -f env.yaml -g $RESOURCE_GROUP -w $WORKSPACE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efc422b7",
      "metadata": {},
      "source": [
        "Wait until the environment creation is complete. The next step will fail if the environment is not ready."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f6e38a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Run NCCL test job in AzureML\n",
        "\n",
        "az ml environment show -n nccltest_wrapper --version 1 > /dev/null\n",
        "az ml job create -f job.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aa5507a",
      "metadata": {},
      "source": [
        "### Expected Results\n",
        "\n",
        "You should expect to see a bus bandwidth of around **147** in the output of the job in process_0 logs. Note that we take the maximum speed achieved as indicator of hardware speed, as this means the algorithm has managed to load the hardware appropriately at those settings.\n",
        "\n",
        "Avg bus bandwidth    : 147.439\n",
        "\n",
        "This confirms that IB is usable on the cluster with AML, and has optimum performance."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
